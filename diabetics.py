# -*- coding: utf-8 -*-
"""Diabetics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1riEj5qs93qS6YDRv7jT1qADqrPpaJKGn
"""

from google.colab import files
upload=files.upload()

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv("diabetes (1).csv")
df

import numpy as np

zero_invalid_cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]

df[zero_invalid_cols] = df[zero_invalid_cols].replace(0, np.nan)

df[zero_invalid_cols] = df[zero_invalid_cols].fillna(df[zero_invalid_cols].median())

df

print(df.isnull().sum().sum())      ########## no null values

df["Age_Group"] = pd.cut(df["Age"],bins=[20, 30, 40, 50, 100],labels=[0, 1, 2, 3]).astype(int)
df["BMI_Category"] = pd.cut(df["BMI"],bins=[0, 18.5, 25, 30, 100],labels=[0, 1, 2, 3]).astype(int)
df["Glucose_Insulin_Ratio"] = df["Glucose"] / df["Insulin"]

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import BorderlineSMOTE


###Feature and target
x=df.drop(["Outcome"], axis=1)
y=df["Outcome"]


#### No use of target label encoder since Outcome is already 0/1 numeric, perfect for classification.

## train test split
x_train, x_test, y_train, y_test =train_test_split(x,y, random_state=42, test_size=0.2, stratify=y)
scaler=StandardScaler()
x_train_scaled=scaler.fit_transform(x_train)
x_test_scaled=scaler.transform(x_test)


sm=BorderlineSMOTE(random_state=42)
x_train_resample, y_train_resample=sm.fit_resample(x_train_scaled, y_train)
print("x_train_resample:", x_train_resample)
print("y_train_resample:", y_train_resample)

print(pd.Series(y_train).value_counts())
print(pd.Series(y_train_resample).value_counts())

!pip install catboost --quiet

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import *
from catboost import CatBoostClassifier


models = {
    "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42),

    "DecisionTree": DecisionTreeClassifier(random_state=42, class_weight="balanced"),

    "RandomForest": RandomForestClassifier(random_state=42, class_weight="balanced"),

    "CatBoost": CatBoostClassifier(random_state=42, verbose=0)
}


for name, model in models.items():

    print("\n" + "=" * 70)
    print(f"MODEL: {name}")
    print("=" * 70)


    # Train
    model.fit(x_train_resample, y_train_resample)


    # Predictions
    y_train_pred = model.predict(x_train_resample)
    y_test_pred  = model.predict(x_test_scaled)


    y_train_prob = model.predict_proba(x_train_resample)
    y_test_prob  = model.predict_proba(x_test_scaled)


    # Log Loss
    train_logloss = log_loss(y_train_resample, y_train_prob)
    test_logloss  = log_loss(y_test, y_test_prob)


    # Overall Metrics
    train_acc = accuracy_score(y_train_resample, y_train_pred)
    test_acc  = accuracy_score(y_test, y_test_pred)

    print(f"Train Log Loss : {train_logloss:.4f}")
    print(f"Test  Log Loss : {test_logloss:.4f}")
    print(f"Train Accuracy : {train_acc:.4f}")
    print(f"Test  Accuracy : {test_acc:.4f}\n")


    # Class-wise Metrics (0 & 1)
    classes = [0, 1]

    for cls in classes:
        precision = precision_score(y_test, y_test_pred, pos_label=cls)
        recall    = recall_score(y_test, y_test_pred, pos_label=cls)
        f1        = f1_score(y_test, y_test_pred, pos_label=cls)

        roc_auc   = roc_auc_score(y_test == cls, y_test_prob[:, cls])

        print(f"Class {cls}")
        print(f"  Precision : {precision:.4f}")
        print(f"  Recall    : {recall:.4f}")
        print(f"  F1-Score  : {f1:.4f}")
        print(f"  ROC-AUC   : {roc_auc:.4f}\n")


    # Confusion Matrix
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_test_pred))

"""CatBoost was selected as the final model because it achieved the highest recall (0.7778) and F1-score (0.7000) for the diabetic class, which is critical in medical prediction tasks where missing positive cases is costly. It also demonstrated strong discriminative power (ROC-AUC = 0.8348), outperforming Logistic Regression and remaining competitive with Random Forest. Additionally, CatBoost maintained acceptable probability reliability (test log loss = 0.4941) without severe overfitting. Overall, it provided the best balance between sensitivity, accuracy, and generalization for diabetes risk prediction."""

#Predictions and probabilities
y_prediction = model.predict(x_test_scaled)
y_probability = model.predict_proba(x_test_scaled)[:, 1]



# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_probability)

# Find optimal threshold using Youden’s J statistic (tpr - fpr)
optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]

# Print result
print("Optimal Threshold:", optimal_threshold)


y_pred_optimal = (y_probability >= optimal_threshold).astype(int)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

# probability scores from CatBoost
y_probability = models["CatBoost"].predict_proba(x_test_scaled)[:, 1]

#ROC curve values
fpr, tpr, thresholds = roc_curve(y_test, y_probability)

# AUC score
roc_auc = roc_auc_score(y_test, y_probability)

# Plot ROC Curve
plt.figure()
plt.plot(fpr, tpr, label=f"CatBoost ROC Curve (AUC = {roc_auc:.4f})")
plt.plot([0, 1], [0, 1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC–AUC Curve for CatBoost")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd

test_data = pd.DataFrame({
    "Pregnancies": [2, 5, 1, 8, 3],
    "Glucose": [120, 160, 95, 180, 140],
    "BloodPressure": [70, 78, 65, 90, 75],
    "SkinThickness": [25, 32, 20, 35, 28],
    "Insulin": [85, 140, 60, 200, 120],
    "BMI": [26.5, 34.2, 22.1, 38.0, 30.5],
    "DiabetesPedigreeFunction": [0.45, 0.85, 0.20, 1.50, 0.60],
    "Age": [28, 45, 22, 55, 35],
    "Age_Group": [0, 2, 0, 3, 1],
    "BMI_Category": [1, 3, 1, 3, 2],
    "Glucose_Insulin_Ratio": [
        120/85,
        160/140,
        95/60,
        180/200,
        140/120
    ]
})


test_data_scaled = scaler.transform(test_data)

# Predictions (0 = Non-Diabetic, 1 = Diabetic)
test_predictions = models["CatBoost"].predict(test_data_scaled)

# Prediction Probabilities
test_probabilities = models["CatBoost"].predict_proba(test_data_scaled)[:, 1]

# Show Results
test_results = test_data.copy()
test_results["Predicted_Outcome"] = test_predictions
test_results["Diabetes_Probability"] = test_probabilities

print(test_results)

import joblib

# Get your final CatBoost model
cat_model = models["CatBoost"]

# Save CatBoost model
cat_model.save_model("catboost_diabetes.cbm")

# Save scaler
joblib.dump(scaler, "scaler.pkl")